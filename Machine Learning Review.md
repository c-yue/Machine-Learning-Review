


<br>



#### General

##### Definition
- learn a target function f that maps input  
variables X to output variable Y, with an error e:  
$ğ‘Œ = f(ğ‘‹) + ğ‘’$

##### Parameters ~= Coeficient ~= Weight
- they determine $f$

##### Aim
- find the best parameters making the $f$ works best  
<=> make the cost/loss small

##### cost function = loss function
- eg. $MSE=1/m \cdot \sum_{i=1}^m(\hat{y_i}-y_i)$  
<=> $MSE=1/m \cdot \sum_{i=1}^m(ğ‘“(x_i)-y_i)$  
$m$: the number of samples 

##### Bias-Variance trade-off
Bias: åè§ï¼Œé¢„æµ‹ç»“æœä¸å®é™…ç»“æœçš„ä¸åŒ  
Variance: æ–¹å·®ï¼Œé¢„æµ‹ç»“æœæœ¬èº«çš„æ³¢åŠ¨ï¼ˆå—è‡ªå˜é‡å½±å“ï¼‰



<br>



#### Optimization

##### Gradient Descent - æ¢¯åº¦ä¸‹é™

- Aim: minimize the cost function, eg. MSE  

- Methodology:
    - æ¢¯åº¦çš„æ–¹å‘æ˜¯å‡½æ•°å¢é•¿é€Ÿåº¦æœ€å¿«çš„æ–¹å‘ï¼Œé‚£ä¹ˆ**æ¢¯åº¦çš„åæ–¹å‘å°±æ˜¯å‡½æ•°å‡å°‘æœ€å¿«çš„æ–¹å‘**ã€‚é‚£ä¹ˆï¼Œå¦‚æœæƒ³**è®¡ç®—ä¸€ä¸ªå‡½æ•°çš„æœ€å°å€¼**ï¼Œå°±å¯ä»¥ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ³•çš„æ€æƒ³æ¥åšã€‚
    - å‡è®¾å¸Œæœ›æ±‚è§£ç›®æ ‡å‡½æ•°çš„æœ€å°å€¼ï¼š $f({x})=f(x_{1},\cdots,x_{n})$  
        å¯ä»¥ä»ä¸€ä¸ªåˆå§‹ç‚¹ ${x}^{(0)}=(x_{1}^{(0)},\cdots,x_{n}^{(0)})$ å¼€å§‹ï¼ŒåŸºäºå­¦ä¹ ç‡ $\eta$ æ„å»ºä¸€ä¸ªè¿­ä»£è¿‡ç¨‹ï¼š  

        $x_{1}^{(i+1)} = x_{1}^{(i)} - \eta\cdot \frac{\partial f}{\partial x_{1}}({x}^{(i)})$,  
        $\cdots$  
        $x_{n}^{(i+1)} = x_{n}^{(i)} - \eta\cdot \frac{\partial f}{\partial x_{n}}({x}^{(i)})$  
        
    - å…¶ä¸­ ${x}^{(i)} = (x_{1}^{(i)},\cdots,x_{n}^{(i)})$ ï¼Œä¸€æ—¦è¾¾åˆ°æ”¶æ•›æ¡ä»¶ï¼Œè¿­ä»£å°±ç»“æŸã€‚

    ![plot](./images/gradient_decent.jpg)

- Batch Gradient Descent - æ‰¹é‡æ¢¯åº¦ä¸‹é™
    - use samples/batch for every iteration
- Stochastic Gradient Descent - SGD - éšæœºæ¢¯åº¦ä¸‹é™
    - use random samples/batch for every iteration
- **Algorithmn porcess of SGD**:  
    - Required: learning rate $\eta$, initialized parameters $\theta$
    - Repeat
        1. **select random m samples/batch from training set**:  
        samples with features ${x^{(1)},\cdots,x^{(m)}}$ and lables ${y^{(1)}, \cdots, y^{(m)}}$  
        2. **calculate gradient**:  
        $g = \nabla_{\theta} \sum_{i=1}^m L(f(x^{(i)};\theta), y^{(i)})/m $  
        3. **parameters update**:  
        $\theta = \theta - \eta \cdot g$  
    - Until converge condition achieved


##### Ordinary Least Squares



##### Maximum Likelihood Estimation

PS: review linear algebra



<br>



#### Linear Algorithms
##### Linear Regression
##### Logistic Regression
##### Linear Discriminant Analysis



<br>



#### Nonlinear Algorithms
##### Classification and Regression Trees
##### Naive Bayes Classifier
##### K-Nearest Neighbors
##### Support Vector Machines




<br>




#### Ensemble Algorithms
##### Bagging and Random Forest
##### Boosting and AdaBoost





















